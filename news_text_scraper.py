"""
ë‰´ìŠ¤ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ë„êµ¬ (ìµœì í™” ë²„ì „)

ì‚¬ìš©ë²•:
    article = extract_article(url)

ë°˜í™˜ í˜•ì‹ (JSON):
    {
        'title': 'ê¸°ì‚¬ ì œëª©',
        'text': 'ê¸°ì‚¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸',
        'image_url': 'ëŒ€í‘œ ì´ë¯¸ì§€ URL'
    }

ì˜ì¡´ì„±: pip3 install trafilatura newspaper3k playwright beautifulsoup4 requests fake-useragent extruct
Playwright ì´ˆê¸° ì„¤ì¹˜: playwright install chromium

ì„±ëŠ¥ ìµœì  ìˆœì„œ:
1. Trafilatura (ê°€ì¥ ë¹ ë¥´ê³  ì •í™•, ì •ì  ì½˜í…ì¸ )
2. Newspaper3k (ë¹ ë¥´ê³  í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜)
3. Playwright + Trafilatura (JavaScript ë Œë”ë§ í•„ìš”ì‹œ)
4. Playwright + Newspaper3k (ëŒ€ì²´ ë°©ë²•)
"""

import json
import time
from typing import Optional, Dict
from urllib.parse import urljoin

import requests
import trafilatura
from bs4 import BeautifulSoup
from newspaper import Article

try:
    from fake_useragent import UserAgent
    ua = UserAgent()
    USER_AGENT = ua.random
except ImportError:
    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'

try:
    from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸  Playwright ë¯¸ì„¤ì¹˜ - JavaScript ë Œë”ë§ ê¸°ëŠ¥ ë¹„í™œì„±í™”")

try:
    import extruct
    EXTRUCT_AVAILABLE = True
except ImportError:
    EXTRUCT_AVAILABLE = False

# HTTP í—¤ë” ì„¤ì •
HEADERS = {
    'User-Agent': USER_AGENT,
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
    'Accept-Encoding': 'gzip, deflate',
    'DNT': '1',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1',
}

def fetch_with_headers(url: str) -> str:
    """HTTP í—¤ë”ë¥¼ í¬í•¨í•œ URL ìš”ì²­"""
    response = requests.get(url, headers=HEADERS, timeout=30)
    response.raise_for_status()
    return response.text

def extract_images_from_html(html: str, base_url: str = "") -> Optional[str]:
    """HTMLì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)"""
    soup = BeautifulSoup(html, 'html.parser')

    # 1. og:image ë©”íƒ€íƒœê·¸
    og_image = soup.find('meta', property='og:image')
    if og_image and og_image.get('content'):
        return og_image.get('content')

    # 2. twitter:image
    tw_image = soup.find('meta', attrs={'name': 'twitter:image'})
    if tw_image and tw_image.get('content'):
        return tw_image.get('content')

    # 3. extructë¡œ JSON-LD íŒŒì‹±
    if EXTRUCT_AVAILABLE:
        try:
            metadata = extruct.extract(html, base_url=base_url)
            # Schema.org ImageObject ì°¾ê¸°
            for item in metadata.get('json-ld', []):
                if isinstance(item, dict):
                    if item.get('image'):
                        img = item['image']
                        if isinstance(img, str):
                            return img
                        elif isinstance(img, dict) and img.get('url'):
                            return img['url']
                        elif isinstance(img, list) and len(img) > 0:
                            return img[0] if isinstance(img[0], str) else img[0].get('url')
        except:
            pass

    # 4. article ë‚´ë¶€ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€
    article_imgs = soup.select('article img[src], .article img[src], #article img[src]')
    if article_imgs:
        src = article_imgs[0].get('src')
        return urljoin(base_url, src) if src else None

    # 5. ì¼ë°˜ img íƒœê·¸
    imgs = soup.find_all('img', src=True)
    for img in imgs:
        src = img.get('src')
        # ë¡œê³ , ì•„ì´ì½˜ ì œì™¸
        if src and not any(x in src.lower() for x in ['logo', 'icon', 'avatar', 'profile', 'ad', 'banner']):
            # ìµœì†Œ í¬ê¸° í™•ì¸ (width/height ì†ì„±)
            width = img.get('width', '0')
            height = img.get('height', '0')
            try:
                if int(width) >= 200 or int(height) >= 200:
                    return urljoin(base_url, src)
            except:
                return urljoin(base_url, src)

    return None

def extract_trafilatura(url: str) -> Optional[Dict[str, str]]:
    """Trafilatura ê¸°ì‚¬ ì¶”ì¶œ"""
    try:
        html = fetch_with_headers(url)
        result = trafilatura.extract(html, output_format='json', url=url,
                                    include_images=True, include_links=True)
        if result:
            data = json.loads(result)
            image_url = data.get('image') or extract_images_from_html(html, url)

            return {
                'title': data.get('title'),
                'text': data.get('text'),
                'image_url': image_url
            }
    except Exception as e:
        print(f"Trafilatura ì‹¤íŒ¨: {e}")
    return None

def extract_newspaper(url: str) -> Optional[Dict[str, str]]:
    """Newspaper3k ê¸°ì‚¬ ì¶”ì¶œ"""
    try:
        html = fetch_with_headers(url)
        article = Article(url)
        article.config.browser_user_agent = HEADERS['User-Agent']
        article.set_html(html)
        article.parse()

        image_url = article.top_image or extract_images_from_html(html, url)

        return {
            'title': article.title,
            'text': article.text,
            'image_url': image_url
        }
    except Exception as e:
        print(f"Newspaper3k ì‹¤íŒ¨: {e}")
    return None

def get_rendered_html_playwright(url: str, wait: int = 2) -> Optional[str]:
    """Playwrightë¡œ ë Œë”ë§ëœ HTML ê°€ì ¸ì˜¤ê¸°"""
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                user_agent=HEADERS['User-Agent'],
                viewport={'width': 1920, 'height': 1080}
            )
            page = context.new_page()
            page.goto(url, wait_until='domcontentloaded', timeout=30000)
            time.sleep(wait)
            html = page.content()
            browser.close()
            return html
    except Exception as e:
        print(f"Playwright ì˜¤ë¥˜: {e}")
        return None

def extract_playwright_trafilatura(url: str) -> Optional[Dict[str, str]]:
    """Playwright + Trafilatura ì¡°í•©"""
    try:
        html = get_rendered_html_playwright(url)
        if html:
            result = trafilatura.extract(html, output_format='json', url=url,
                                        include_images=True, include_links=True)
            if result:
                data = json.loads(result)
                image_url = data.get('image') or extract_images_from_html(html, url)

                return {
                    'title': data.get('title'),
                    'text': data.get('text'),
                    'image_url': image_url
                }
    except Exception as e:
        print(f"Playwright+Trafilatura ì‹¤íŒ¨: {e}")
    return None

def extract_playwright_newspaper(url: str) -> Optional[Dict[str, str]]:
    """Playwright + Newspaper3k ì¡°í•©"""
    try:
        html = get_rendered_html_playwright(url)
        if html:
            article = Article(url='')
            article.set_html(html)
            article.parse()

            image_url = article.top_image or extract_images_from_html(html, url)

            return {
                'title': article.title,
                'text': article.text,
                'image_url': image_url
            }
    except Exception as e:
        print(f"Playwright+Newspaper3k ì‹¤íŒ¨: {e}")
    return None


def extract_article(url: str) -> Optional[Dict[str, str]]:
    """ê¸°ì‚¬ ì¶”ì¶œ - ìµœì  ìˆœì„œë¡œ ì‹œë„"""
    print(f"ğŸ” ì¶”ì¶œ ì‹œì‘: {url}")

    result = {'title': None, 'text': None, 'image_url': None}

    # ìµœì  ìˆœì„œ: ë¹ ë¥´ê³  ì •í™•í•œ ê²ƒë¶€í„° ì‹œë„
    # 1. Trafilatura - ê°€ì¥ ë¹ ë¥´ê³  ì •í™• (ì •ì  ì½˜í…ì¸ )
    # 2. Newspaper3k - ë¹ ë¥´ê³  í•œêµ­ì–´ ì§€ì› ìš°ìˆ˜
    # 3. Playwright + Trafilatura - JavaScript ë Œë”ë§ì´ í•„ìš”í•œ ê²½ìš°
    # 4. Playwright + Newspaper3k - ëŒ€ì²´ ë°©ë²•
    extractors = [
        ("Trafilatura", extract_trafilatura),
        ("Newspaper3k", extract_newspaper),
    ]

    # Playwright ì¶”ê°€ (JavaScript ë Œë”ë§ í•„ìš”ì‹œ)
    if PLAYWRIGHT_AVAILABLE:
        extractors.extend([
            ("Playwright+Trafilatura", extract_playwright_trafilatura),
            ("Playwright+Newspaper3k", extract_playwright_newspaper),
        ])

    for i, (name, extractor) in enumerate(extractors, 1):
        print(f"   {i}ï¸âƒ£ {name} ì‹œë„...")
        try:
            data = extractor(url)
            if data:
                # ê²°ê³¼ ì—…ë°ì´íŠ¸
                updated = []
                for key in result:
                    if not result[key] and data.get(key):
                        result[key] = data[key]
                        updated.append(key)

                if updated:
                    print(f"      â†’ ì¶”ì¶œ ì„±ê³µ: {', '.join(updated)}")

                # ì œëª©, ë³¸ë¬¸, ì´ë¯¸ì§€ ëª¨ë‘ ìˆìœ¼ë©´ ì„±ê³µ
                if result['title'] and result['text'] and result['image_url']:
                    print(f"   âœ… {name} ì™„ë£Œ! (ì œëª© O, ë³¸ë¬¸ O, ì´ë¯¸ì§€ O)")
                    return result

                # ìƒíƒœ ì¶œë ¥
                status = f"ì œëª©: {'O' if result['title'] else 'X'}, ë³¸ë¬¸: {'O' if result['text'] else 'X'}, ì´ë¯¸ì§€: {'O' if result['image_url'] else 'X'}"
                if result['title'] and result['text']:
                    print(f"   âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ - ë‹¤ìŒ ë‹¨ê³„ ê³„ì† ({status})")
                else:
                    print(f"   âš ï¸ ë¶€ë¶„ ì„±ê³µ ({status})")
            else:
                print(f"   âŒ {name} ì‹¤íŒ¨")
        except requests.HTTPError as e:
            if e.response.status_code in (403, 429):
                print(f"   âŒ {name} ì°¨ë‹¨ë¨ (HTTP {e.response.status_code})")
                raise
            print(f"   âŒ {name} ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"   âŒ {name} ì˜¤ë¥˜: {e}")

    if result['title'] or result['text']:
        print(f"   âœ… ìµœì¢… ê²°ê³¼ - ì œëª©: {'O' if result['title'] else 'X'}, ë³¸ë¬¸: {'O' if result['text'] else 'X'}, ì´ë¯¸ì§€: {'O' if result['image_url'] else 'X'}")
        return result

    print("   âŒ ëª¨ë“  ë°©ë²• ì‹¤íŒ¨")
    return None

if __name__ == "__main__":
    test_urls = [
        "https://www.chosun.com/national/education/2025/07/19/4OMZBICJSNDGXA567IKPRBUFKA/",
        "https://news.nate.com/view/20250521n37437",
        "https://www.hani.co.kr/arti/society/society_general/1204840.html"
    ]

    print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:")
    print(f"  - Playwright: {'âœ…' if PLAYWRIGHT_AVAILABLE else 'âŒ'}")
    print(f"  - Extruct: {'âœ…' if EXTRUCT_AVAILABLE else 'âŒ'}")
    print(f"  - Fake UserAgent: {'âœ…' if 'ua' in dir() else 'âŒ'}\n")

    for url in test_urls:
        print(f"\n{'='*60}")
        try:
            article = extract_article(url)
            if article:
                print(f"\nğŸ“„ ì œëª©: {article.get('title', 'N/A')[:100]}...")
                print(f"ğŸ“ ë³¸ë¬¸: {len(article.get('text', ''))}ì")
                print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€: {article.get('image_url', 'N/A')[:80]}..." if article.get('image_url') else "ğŸ–¼ï¸ ì´ë¯¸ì§€: ì—†ìŒ")
            else:
                print("ì¶”ì¶œ ì‹¤íŒ¨")
        except Exception as e:
            print(f"ì „ì²´ ì‹¤íŒ¨: {e}")
        print("="*60)
